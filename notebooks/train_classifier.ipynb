{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training Notebook\n",
    "## Train XGBoost and Meta-Model for Trading Signals\n",
    "\n",
    "This notebook trains machine learning models for the quantitative trading bot:\n",
    "1. **Primary Classifier**: XGBoost model with triple-barrier labeling\n",
    "2. **Meta-Model**: Secondary filter model for trade acceptance/rejection\n",
    "3. **Model Calibration**: Platt and Isotonic calibration for probability outputs\n",
    "4. **Cross-Validation**: Purged K-fold validation for time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import yaml\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import brier_score_loss, confusion_matrix, roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import our modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from algos.core.cv_utils import PurgedKFold, combinatorial_purged_cv\n",
    "from algos.core.feature_pipe import FeaturePipeline\n",
    "from algos.core.labels import TripleBarrierLabeler, create_meta_labels\n",
    "\n",
    "# Set style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open(\"../config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Features: {list(config['trading']['features'].keys())}\")\n",
    "print(f\"Labels: {config['trading']['labels']}\")\n",
    "\n",
    "# Initialize components\n",
    "feature_pipeline = FeaturePipeline(config[\"trading\"])\n",
    "labeler = TripleBarrierLabeler(config[\"trading\"])\n",
    "\n",
    "print(\"Components initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for demonstration\n",
    "# In practice, you would load real market data here\n",
    "\n",
    "def generate_synthetic_data(n_samples=5000, n_symbols=5):\n",
    "    \"\"\"Generate synthetic market data for training.\"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range(\"2020-01-01\", periods=n_samples, freq=\"30min\")\n",
    "\n",
    "    all_data = {}\n",
    "\n",
    "    for i in range(n_symbols):\n",
    "        symbol = f\"SYMBOL_{i}\"\n",
    "\n",
    "        # Generate price data with realistic properties\n",
    "        returns = np.random.normal(0, 0.02, n_samples)  # 2% volatility\n",
    "        returns += 0.1 * np.sin(np.arange(n_samples) * 2 * np.pi / 100)  # Trend component\n",
    "\n",
    "        prices = 100 * np.exp(np.cumsum(returns))\n",
    "\n",
    "        # Generate OHLCV data\n",
    "        data = pd.DataFrame({\n",
    "            \"close\": prices,\n",
    "            \"high\": prices * (1 + np.abs(np.random.normal(0, 0.005, n_samples))),\n",
    "            \"low\": prices * (1 - np.abs(np.random.normal(0, 0.005, n_samples))),\n",
    "            \"volume\": np.random.lognormal(10, 1, n_samples)\n",
    "        }, index=dates)\n",
    "\n",
    "        data[\"open\"] = data[\"close\"].shift(1).fillna(data[\"close\"][0])\n",
    "\n",
    "        all_data[symbol] = data\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Generate data\n",
    "market_data = generate_synthetic_data(5000, 5)\n",
    "print(f\"Generated data for {len(market_data)} symbols\")\n",
    "print(f\"Sample data shape: {list(market_data.values())[0].shape}\")\n",
    "\n",
    "# Display sample data\n",
    "sample_symbol = list(market_data.keys())[0]\n",
    "print(f\"\\nSample data for {sample_symbol}:\")\n",
    "print(market_data[sample_symbol].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features for all symbols\n",
    "all_features = {}\n",
    "all_labels = {}\n",
    "\n",
    "for symbol, data in market_data.items():\n",
    "    print(f\"Processing {symbol}...\")\n",
    "\n",
    "    # Generate features\n",
    "    features = feature_pipeline.build_features(data)\n",
    "\n",
    "    if len(features) > 100:  # Ensure sufficient data\n",
    "        all_features[symbol] = features\n",
    "\n",
    "        # Generate labels\n",
    "        labels, touch_times, barriers_df = labeler.fit_transform(\n",
    "            data[\"close\"], features[\"atr\"]\n",
    "        )\n",
    "\n",
    "        all_labels[symbol] = labels\n",
    "\n",
    "        print(f\"  Features shape: {features.shape}\")\n",
    "        print(f\"  Labels shape: {labels.shape}\")\n",
    "        print(f\"  Label distribution: {labels.value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nFeature generation complete for {len(all_features)} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features and labels\n",
    "combined_features = pd.concat(all_features.values(), axis=0)\n",
    "combined_labels = pd.concat(all_labels.values(), axis=0)\n",
    "\n",
    "# Align features and labels\n",
    "aligned_features, aligned_labels = combined_features.align(combined_labels, join=\"inner\")\n",
    "\n",
    "print(\"Combined dataset:\")\n",
    "print(f\"Features shape: {aligned_features.shape}\")\n",
    "print(f\"Labels shape: {aligned_labels.shape}\")\n",
    "print(f\"Combined label distribution: {aligned_labels.value_counts().to_dict()}\")\n",
    "\n",
    "# Handle missing values\n",
    "aligned_features = aligned_features.fillna(0)\n",
    "aligned_features = aligned_features.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(\"Missing values handled\")\n",
    "print(f\"Feature columns: {list(aligned_features.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to binary (1 for profit, 0 for loss/timeout)\n",
    "binary_labels = (aligned_labels == 1).astype(int)\n",
    "\n",
    "print(\"Binary label distribution:\")\n",
    "print(f\"Positive (profit): {binary_labels.sum()} ({binary_labels.mean():.1%})\")\n",
    "print(f\"Negative (loss/timeout): {(~binary_labels.astype(bool)).sum()} ({(~binary_labels).mean():.1%})\")\n",
    "\n",
    "# Set up purged cross-validation\n",
    "cv = PurgedKFold(n_splits=5, embargo_frac=0.02)\n",
    "\n",
    "# XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "print(\"Starting XGBoost training with purged CV...\")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = combinatorial_purged_cv(\n",
    "    X=aligned_features,\n",
    "    y=binary_labels,\n",
    "    model=xgb_model,\n",
    "    n_splits=5,\n",
    "    embargo_frac=0.02\n",
    ")\n",
    "\n",
    "print(\"\\nCross-validation results:\")\n",
    "for metric, stats in cv_results[\"cv_stats\"].items():\n",
    "    print(f\"{metric}: {stats['mean']:.4f} Â± {stats['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full dataset\n",
    "print(\"Training final XGBoost model...\")\n",
    "\n",
    "xgb_model.fit(\n",
    "    aligned_features,\n",
    "    binary_labels,\n",
    "    eval_set=[(aligned_features, binary_labels)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "train_predictions = xgb_model.predict_proba(aligned_features)[:, 1]\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": aligned_features.columns,\n",
    "    \"importance\": xgb_model.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(10), feature_importance.head(10)[\"importance\"])\n",
    "plt.yticks(range(10), feature_importance.head(10)[\"feature\"])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Top 10 Feature Importances - XGBoost\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Model training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate model probabilities\n",
    "print(\"Calibrating model probabilities...\")\n",
    "\n",
    "# Platt calibration\n",
    "platt_calibrator = CalibratedClassifierCV(xgb_model, method=\"sigmoid\", cv=3)\n",
    "platt_calibrator.fit(aligned_features, binary_labels)\n",
    "\n",
    "# Isotonic calibration\n",
    "isotonic_calibrator = CalibratedClassifierCV(xgb_model, method=\"isotonic\", cv=3)\n",
    "isotonic_calibrator.fit(aligned_features, binary_labels)\n",
    "\n",
    "# Get calibrated predictions\n",
    "platt_predictions = platt_calibrator.predict_proba(aligned_features)[:, 1]\n",
    "isotonic_predictions = isotonic_calibrator.predict_proba(aligned_features)[:, 1]\n",
    "\n",
    "# Calibration plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original calibration\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    binary_labels, train_predictions, n_bins=10\n",
    ")\n",
    "axes[0].plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"XGBoost\")\n",
    "axes[0].plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "axes[0].set_ylabel(\"Fraction of positives\")\n",
    "axes[0].set_xlabel(\"Mean predicted probability\")\n",
    "axes[0].set_title(\"Original Model\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Platt calibration\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    binary_labels, platt_predictions, n_bins=10\n",
    ")\n",
    "axes[1].plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Platt\")\n",
    "axes[1].plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "axes[1].set_xlabel(\"Mean predicted probability\")\n",
    "axes[1].set_title(\"Platt Calibration\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Isotonic calibration\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    binary_labels, isotonic_predictions, n_bins=10\n",
    ")\n",
    "axes[2].plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Isotonic\")\n",
    "axes[2].plot([0, 1], [0, 1], \"k:\", label=\"Perfect calibration\")\n",
    "axes[2].set_xlabel(\"Mean predicted probability\")\n",
    "axes[2].set_title(\"Isotonic Calibration\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate Brier scores\n",
    "original_brier = brier_score_loss(binary_labels, train_predictions)\n",
    "platt_brier = brier_score_loss(binary_labels, platt_predictions)\n",
    "isotonic_brier = brier_score_loss(binary_labels, isotonic_predictions)\n",
    "\n",
    "print(\"\\nBrier Scores (lower is better):\")\n",
    "print(f\"Original: {original_brier:.4f}\")\n",
    "print(f\"Platt: {platt_brier:.4f}\")\n",
    "print(f\"Isotonic: {isotonic_brier:.4f}\")\n",
    "\n",
    "# Choose best calibration method\n",
    "if platt_brier < isotonic_brier:\n",
    "    final_model = platt_calibrator\n",
    "    calibration_method = \"platt\"\n",
    "else:\n",
    "    final_model = isotonic_calibrator\n",
    "    calibration_method = \"isotonic\"\n",
    "\n",
    "print(f\"\\nSelected {calibration_method} calibration (best Brier score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Meta-Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta-labels\n",
    "print(\"Creating meta-labels...\")\n",
    "\n",
    "# Get primary model predictions\n",
    "primary_predictions = final_model.predict_proba(aligned_features)[:, 1]\n",
    "\n",
    "# Convert original triple-barrier labels to binary for meta-labeling\n",
    "meta_labels = create_meta_labels(pd.Series(primary_predictions, index=aligned_labels.index),\n",
    "                                aligned_labels, threshold=0.5)\n",
    "\n",
    "print(f\"Meta-labels created: {len(meta_labels)} samples\")\n",
    "print(f\"Meta-label acceptance rate: {meta_labels.mean():.1%}\")\n",
    "\n",
    "# Prepare meta-features\n",
    "meta_features = pd.DataFrame({\n",
    "    \"primary_prob\": primary_predictions,\n",
    "    \"atr_ratio\": aligned_features[\"atr\"] / aligned_features.get(\"sma_20\", 100),\n",
    "    \"realized_vol\": aligned_features.get(\"realized_vol\", 0.1),\n",
    "    \"rsi_normalized\": aligned_features.get(\"rsi\", 50) / 100,\n",
    "    \"bb_position\": aligned_features.get(\"bb_position\", 0.5)\n",
    "})\n",
    "\n",
    "meta_features = meta_features.fillna(0)\n",
    "\n",
    "print(f\"Meta-features shape: {meta_features.shape}\")\n",
    "print(f\"Meta-features columns: {list(meta_features.columns)}\")\n",
    "\n",
    "# Train meta-model\n",
    "meta_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training meta-model...\")\n",
    "meta_model.fit(meta_features, meta_labels)\n",
    "\n",
    "# Meta-model predictions\n",
    "meta_predictions = meta_model.predict(meta_features)\n",
    "meta_probabilities = meta_model.predict_proba(meta_features)[:, 1]\n",
    "\n",
    "print(\"\\nMeta-model performance:\")\n",
    "print(f\"Accuracy: {(meta_predictions == meta_labels).mean():.3f}\")\n",
    "print(f\"Precision: {(meta_predictions & meta_labels).sum() / meta_predictions.sum():.3f}\")\n",
    "print(f\"Recall: {(meta_predictions & meta_labels).sum() / meta_labels.sum():.3f}\")\n",
    "\n",
    "# Meta-model feature importance\n",
    "meta_importance = pd.DataFrame({\n",
    "    \"feature\": meta_features.columns,\n",
    "    \"importance\": meta_model.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nMeta-model feature importance:\")\n",
    "print(meta_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model evaluation\n",
    "print(\"=== MODEL EVALUATION ===\")\n",
    "\n",
    "# Primary model metrics\n",
    "final_predictions = final_model.predict_proba(aligned_features)[:, 1]\n",
    "binary_predictions = (final_predictions > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nPrimary Model Metrics:\")\n",
    "print(f\"AUC Score: {roc_auc_score(binary_labels, final_predictions):.4f}\")\n",
    "print(f\"Brier Score: {brier_score_loss(binary_labels, final_predictions):.4f}\")\n",
    "print(f\"Accuracy: {(binary_predictions == binary_labels).mean():.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(binary_labels, binary_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Primary Model\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(binary_labels, final_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc_score(binary_labels, final_predictions):.3f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Primary Model\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Prediction distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(final_predictions[binary_labels == 0], alpha=0.7, label=\"Negative\", bins=30)\n",
    "plt.hist(final_predictions[binary_labels == 1], alpha=0.7, label=\"Positive\", bins=30)\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Prediction Distribution\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(meta_probabilities, alpha=0.7, bins=30, color=\"green\")\n",
    "plt.xlabel(\"Meta-Model Probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Meta-Model Probability Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Save primary model\n",
    "primary_model_path = \"../models/xgb.pkl\"\n",
    "joblib.dump(final_model, primary_model_path)\n",
    "print(f\"Primary model saved to {primary_model_path}\")\n",
    "\n",
    "# Save meta-model\n",
    "meta_model_path = \"../models/meta.pkl\"\n",
    "joblib.dump(meta_model, meta_model_path)\n",
    "print(f\"Meta-model saved to {meta_model_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "model_metadata = {\n",
    "    \"primary_model\": {\n",
    "        \"type\": \"XGBoost\",\n",
    "        \"calibration\": calibration_method,\n",
    "        \"features\": list(aligned_features.columns),\n",
    "        \"n_features\": len(aligned_features.columns),\n",
    "        \"training_samples\": len(aligned_features),\n",
    "        \"auc_score\": roc_auc_score(binary_labels, final_predictions),\n",
    "        \"brier_score\": brier_score_loss(binary_labels, final_predictions)\n",
    "    },\n",
    "    \"meta_model\": {\n",
    "        \"type\": \"XGBoost\",\n",
    "        \"features\": list(meta_features.columns),\n",
    "        \"acceptance_rate\": meta_labels.mean(),\n",
    "        \"accuracy\": (meta_predictions == meta_labels).mean()\n",
    "    },\n",
    "    \"training_config\": config[\"trading\"]\n",
    "}\n",
    "\n",
    "metadata_path = \"../models/model_metadata.yaml\"\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    yaml.dump(model_metadata, f, default_flow_style=False)\n",
    "print(f\"Model metadata saved to {metadata_path}\")\n",
    "\n",
    "print(\"\\n=== TRAINING COMPLETE ===\")\n",
    "print(f\"Primary model AUC: {model_metadata['primary_model']['auc_score']:.4f}\")\n",
    "print(f\"Meta-model accuracy: {model_metadata['meta_model']['accuracy']:.4f}\")\n",
    "print(f\"Meta-model acceptance rate: {model_metadata['meta_model']['acceptance_rate']:.1%}\")\n",
    "print(\"\\nModels saved and ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}